<html><head><title>Reductive Reference</title></head><body><h1>Reductive Reference</h1><p><i>Eliezer Yudkowsky, 03 April 2008 01:37AM</i></p><div><p><strong>Followup to</strong>:  <a href="0289.html">Reductionism</a> [http://lesswrong.com/lw/on/reductionism/], <a href="0290.html">Explaining vs. Explaining Away</a> [http://lesswrong.com/lw/oo/explaining_vs_explaining_away/], <a href="0304.html">Hand vs. Fingers</a> [http://lesswrong.com/lw/p2/hand_vs_fingers/], <a href="0306.html">Heat vs. Motion</a> [http://lesswrong.com/lw/p4/heat_vs_motion/]</p> <p>The reductionist thesis (as I formulate it) is that human minds, for reasons of efficiency, use a multi-level map in which we separately <em>think</em> about things like "atoms" and "quarks", "hands" and "fingers", or "heat" and "kinetic energy".  Reality itself, on the other hand, is single-level in the sense that it does not seem to contain atoms as <em>separate, additional, causally efficacious</em> entities <em>over and above</em> quarks.</p> <p>Sadi Carnot formulated the (precursor to) the second law of thermodynamics using the caloric theory of heat, in which heat was just a fluid that flowed from hot things to cold things, produced by fire, making gases expand&#8212;the effects of heat were studied separately from the science of kinetics, considerably before the reduction took place.  If you're trying to design a steam engine, the effects of all those tiny vibrations and collisions which we name "heat" can be summarized into a much simpler description than the full quantum mechanics of the quarks.  Humans compute efficiently, thinking of only significant effects on goal-relevant quantities.</p> <p>But reality itself does seem to use the full quantum mechanics of the quarks.  I <a href="0289.html">once met a fellow</a> [http://lesswrong.com/lw/on/reductionism/] who thought that if you used General Relativity to compute a low-velocity problem, like an artillery shell, GR would give you the <em>wrong answer</em>&#8212;not just a slow answer, but an <em>experimentally wrong</em> answer&#8212;because at low velocities, artillery shells are governed by Newtonian mechanics, not GR.  This is exactly how physics does <em>not</em> work.  Reality just seems to go on crunching through General Relativity, even when it only makes a difference at the fourteenth decimal place, which a human would regard as a huge waste of computing power.  Physics does it with brute force.  No one has <em>ever </em>caught physics simplifying its calculations&#8212;or if someone did catch it, the Matrix Lords erased the memory afterward.</p> <p>Our map, then, is very much unlike the territory; our maps are multi-level, the territory is single-level.  Since the representation is so incredibly unlike the referent, in what sense can a belief like "I am wearing socks" be called <em>true,</em> when in reality itself, there are only quarks?</p> <p><a id="more"></a></p> <p>In case you've forgotten what the word "true" means, the classic definition was given by Alfred Tarski:</p> <blockquote> <p>The statement "snow is white" is <em>true</em> if and only if snow is white.</p> </blockquote> <p>In case you've forgotten what the difference is between the statement "I believe 'snow is white'" and "'Snow is white' is true", see <a href="0288.html">here</a> [http://lesswrong.com/lw/om/qualitatively_confused/].  Truth can't be evaluated <em>just</em> by looking inside your own head&#8212;if you want to know, for example, whether "the morning star = the evening star", you need a telescope; it's not enough just to look at the beliefs themselves.</p> <p>This is the point missed by the postmodernist folks screaming, "But how do you <em>know</em> your beliefs are true?"  When you do an experiment, you actually <em>are</em> going outside your own head.  You're engaging in a complex interaction whose outcome is causally determined by the thing you're reasoning about, not just your beliefs about it.  I once <a href="http://yudkowsky.net/bayes/truth.html">defined "reality" as follows</a> [http://yudkowsky.net/bayes/truth.html]:</p> <blockquote> <p>Even when I have a simple hypothesis, strongly supported by all the evidence I know, sometimes I'm still surprised. So I need different names for the thingies that determine my predictions and the thingy that determines my experimental results. I call the former thingies 'belief', and the latter thingy 'reality'."</p> </blockquote> <p>The interpretation of your experiment still depends on your prior beliefs.  I'm not going to talk, for the moment, about Where Priors Come From, because that is not the subject of this blog post.  My point is that truth refers to an <em>ideal</em> comparison between a belief and reality.  Because we understand that planets are distinct from beliefs about planets, we can design an experiment to test whether the belief "the morning star and the evening star are the same planet" is <em>true.</em>  This experiment will involve telescopes, not just introspection, because we understand that "truth" involves comparing an internal belief to an external fact; so we use an instrument, the telescope, whose perceived behavior we believe to depend on the external fact of the planet.</p> <p>Believing that the telescope helps us evaluate the "truth" of "morning star = evening star", relies on our prior beliefs about the telescope interacting with the planet.  Again, I'm not going to address that in this particular blog post, except to quote one of my favorite Raymond Smullyan lines:  "If the more sophisticated reader objects to this statement on the grounds of its being a mere tautology, then please at least give the statement credit for not being inconsistent."  Similarly, I don't see the use of a telescope as circular logic, but as reflective coherence; for every systematic way of arriving at truth, there ought to be a rational explanation for how it works.</p> <p>The question on the table is what it <em>means</em> for "snow is white" to be <em>true,</em> when, in reality, there are just quarks.</p> <p>There's a certain pattern of neural connections making up your beliefs about "snow" and "whiteness"&#8212;we believe this, but we do not know, and cannot concretely visualize, the actual neural connections.  Which are, themselves, embodied in a pattern of quarks even less known.  Out there in the world, there are water molecules whose temperature is low enough that they have arranged themselves in tiled repeating patterns; they look nothing like the tangles of neurons.  In what sense, comparing one (ever-fluctuating) pattern of quarks to the other, is the belief "snow is white" <em>true?</em></p> <p>Obviously, neither I nor anyone else can offer an Ideal Quark Comparer Function that accepts a quark-level description of a neurally embodied belief (including the surrounding brain) and a quark-level description of a snowflake (and the surrounding laws of optics), and outputs "true" or "false" over "snow is white".  And who says the fundamental level is <em>really</em> about particle fields?</p> <p>On the other hand, throwing out all beliefs because they aren't written as gigantic unmanageable specifications about quarks we can't even see... doesn't seem like a very prudent idea.  <a href="0241.html">Not the best way to optimize our goals.</a> [http://lesswrong.com/lw/nb/something_to_protect/] </p> <p>It seems to me that a word like "snow" or "white" can be taken as a kind of promissory note&#8212;not a <em>known</em> specification of exactly which physical quark configurations count as "snow", but, nonetheless, there are <a href="0247.html">things you call snow and things you don't call snow</a> [http://lesswrong.com/lw/nh/extensions_and_intensions/], and even if you got a few items wrong (like plastic snow), an Ideal Omniscient Science Interpreter would see <a href="0251.html">a tight cluster in the center</a> [http://lesswrong.com/lw/nl/the_cluster_structure_of_thingspace/] and <a href="0266.html">redraw the boundary</a> [http://lesswrong.com/lw/o0/where_to_draw_the_boundary/] to have a <a href="0269.html">simpler definition</a> [http://lesswrong.com/lw/o3/superexponential_conceptspace_and_simple_words/].</p> <p>In a single-layer universe whose bottom layer is unknown, or uncertain, or just too large to talk about, the concepts in a multi-layer mind can be said to represent a kind of promissory note&#8212;we don't know <em>what</em> they correspond to, out there.  But it seems to us that we can distinguish positive from negative cases, in a <a href="0268.html">predictively productive way</a> [http://lesswrong.com/lw/o2/mutual_information_and_density_in_thingspace/], so we think&#8212;perhaps in a fully general sense&#8212;that there is <em>some</em> difference of quarks, <em>some</em> difference of configurations at the fundamental level, which explains the differences that feed into our senses, and ultimately result in our saying "snow" or "not snow".</p> <p>I see this white stuff, and it is the same on several occasions, so I hypothesize a stable latent cause in the environment&#8212;I give it the name "snow"; "snow" is then a promissory note referring to a believed-in simple boundary that could be drawn around the unseen causes of my experience.</p> <p>Hilary Putnam's "Twin Earth" thought experiment, where water is not H20 but some strange other substance denoted XYZ, otherwise behaving much like water, and the subsequent philosophical debate, helps to highlight this issue.  "Snow" doesn't have a logical definition known to us&#8212;it's more like an empirically determined pointer to a logical definition.  This is true even if you believe that snow is ice crystals is low-temperature tiled water molecules.  The water molecules are made of quarks.  What if quarks turn out to be made of something else?  What <em>is</em> a snowflake, then?  You don't know&#8212;but it's still a snowflake, not a fire hydrant.</p> <p>And of course, these very paragraphs I have just written, are likewise far above the level of quarks.  "Sensing white stuff, visually categorizing it, and thinking 'snow' or 'not snow'"&#8212;this is also talking very far above the quarks.  So my meta-beliefs are also promissory notes, for things that an Ideal Omniscient Science Interpreter might know about which configurations of the quarks (or whatever) making up my brain, correspond to "believing 'snow is white'".</p> <p>But then, the entire grasp that we have upon reality, is made up of promissory notes of this kind.  So, rather than calling it circular, I prefer to call it self-consistent.</p> <p>This can be a bit unnerving&#8212;maintaining a precarious epistemic perch, in both object-level beliefs and reflection, far above a huge unknown underlying fundamental reality, and hoping one doesn't fall off.</p> <p>On reflection, though, it's hard to see how things could be any other way.</p> <p>So at the end of the day, the statement "reality does not contain hands as fundamental, additional, separate causal entities, over and above quarks" is not the same statement as "hands do not exist" or "I don't have any hands".  There are no <em>fundamental</em> hands; hands are made of fingers, palm, and thumb, which in turn are made of muscle and bone, all the way down to elementary particle fields, which are the fundamental causal entities, so far as we currently know.</p> <p>This is not the same as saying, "there are no 'hands'."  It is not the same as saying, "the word 'hands' is a promissory note that will never be paid, because there is no empirical cluster that corresponds to it"; or "the 'hands' note will never be paid, because it is logically impossible to reconcile its supposed characteristics"; or "the statement 'humans have hands' refers to a sensible state of affairs, but reality is not in that state".</p> <p>Just:  There are patterns that exist <em>in</em> reality where we see "hands", and these patterns have something in common, but they are not fundamental.</p> <p>If I <em>really</em> had no hands&#8212;if reality suddenly transitioned to be in a state that we would describe as "Eliezer has no hands"&#8212;reality would shortly thereafter correspond to a state we would describe as "Eliezer screams as blood jets out of his wrist stumps".</p> <p>And this is <em>true,</em> even though the above paragraph hasn't specified any quark positions.</p> <p>The previous sentence is likewise meta-true.</p> <p>The map is multilevel, the territory is single-level.  This doesn't mean that the higher levels "don't exist", like looking in your garage for a dragon and finding nothing there, or like seeing a mirage in the desert and forming an expectation of drinkable water when there is nothing to drink.  The higher levels of your map are not <em>false,</em> without referent<em>;</em> they have referents <em>in</em> the single level of physics.  It's not that the wings of an airplane unexist&#8212;then the airplane would drop out of the sky.  The "wings of an airplane" exist <em>explicitly</em> in an engineer's multilevel model of an airplane, and the wings of an airplane exist <em>implicitly</em> in the quantum physics of the real airplane.  Implicit existence is not the same as nonexistence.  The exact description of this implicitness is not known to us&#8212;is not explicitly represented in our map.  But this does not prevent our map from working, or even prevent it from being <em>true.</em></p> <p>Though it is a bit unnerving to contemplate that every single concept and belief in your brain, including these meta-concepts about how your brain works and why you can form accurate beliefs, are perched orders and orders of magnitude above reality...<em><br></em></p> <p> </p> <p style="text-align:right">Part of the sequence <a href="http://wiki.lesswrong.com/wiki/Reductionism_%28sequence%29"><em>Reductionism</em></a> [http://wiki.lesswrong.com/wiki/Reductionism_%28sequence%29]</p> <p style="text-align:right">Next post: "<a href="0309.html">Zombies! Zombies?</a> [http://lesswrong.com/lw/p7/zombies_zombies/]"</p> <p style="text-align:right">Previous post: "<a href="0307.html">Brain Breakthrough! It's Made of Neurons!</a> [http://lesswrong.com/lw/p5/brain_breakthrough_its_made_of_neurons/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq12.html">Sequence 12: Reductionism</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0307.html">Brain Breakthrough! It's Made of Neurons!</a></p></td><td><p><i>Next: </i><a href="0477.html">Excluding the Supernatural</a></p></td></tr></table><p><i>Referenced by: </i><a href="0307.html">Brain Breakthrough! It's Made of Neurons!</a> &#8226; <a href="0309.html">Zombies! Zombies?</a> &#8226; <a href="0310.html">Zombie Responses</a> &#8226; <a href="0311.html">The Generalized Anti-Zombie Principle</a> &#8226; <a href="0318.html">Where Philosophy Meets Science</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/p6/reductive_reference/">Reductive Reference</a></p></body></html>